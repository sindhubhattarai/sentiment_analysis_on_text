{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "## Sindhu Bhattarai\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place any addtional functions or constants you need here. \n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# # It's handy to have a full set of emojis\n",
    "\n",
    "all_language_emojis = set()\n",
    "\n",
    "for country in emoji.EMOJI_DATA : \n",
    "    for em in emoji.EMOJI_DATA[country] : \n",
    "        all_language_emojis.add(em)\n",
    "\n",
    "\n",
    "\n",
    "def common_tokens(tokens):\n",
    "    return (Counter(tokens).most_common())\n",
    "\n",
    "    \n",
    "def is_emoji(s):\n",
    "    return(emoji.is_emoji(s))\n",
    "\n",
    "def contains_emoji(s):    \n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "\n",
    "    return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(text, stop_words = sw) :\n",
    "     # modify this function to remove stopwords\n",
    "    return(\" \".join([word for word in text.split(' ') if word not in stop_words ]))\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    text = text.split(\" \")\n",
    "    # modified this function to return tokens of word only \n",
    "    return([words for words in text if words != ''])\n",
    "\n",
    "def remove_song_title(s): \n",
    "    location =  (re.findall(r'\"(.*?)\"', s)[0])\n",
    "    return s.replace(location, '')\n",
    "\n",
    "def get_song_title(s): \n",
    "    location =  (re.findall(r'\"(.*?)\"', str(s))[0])\n",
    "    return location\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.casefold()\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "#data_location = \"/users/chandler/dropbox/teaching/repos/ads-tm-api-scrape/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_files = {'cher':'cher_followers_data.txt',\n",
    "                'robyn':'robynkonichiwa_followers_data.txt'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robyn', 'cher']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists= os.listdir(lyrics_folder)\n",
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_includemeout.txt</td>\n",
       "      <td>\"Include Me Out\"    It is really very simple J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_electric.txt</td>\n",
       "      <td>\"Electric\"    Electric...  It's electric It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_beach2k20.txt</td>\n",
       "      <td>\"Beach 2K20\"    (So you wanna go out? How you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_lovekills.txt</td>\n",
       "      <td>\"Love Kills\"    If you're looking for love Get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_timemachine.txt</td>\n",
       "      <td>\"Time Machine\"    Hey, what did I do? Can't be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   title  \\\n",
       "0  robyn  robyn_includemeout.txt   \n",
       "1  robyn      robyn_electric.txt   \n",
       "2  robyn     robyn_beach2k20.txt   \n",
       "3  robyn     robyn_lovekills.txt   \n",
       "4  robyn   robyn_timemachine.txt   \n",
       "\n",
       "                                              lyrics  \n",
       "0  \"Include Me Out\"    It is really very simple J...  \n",
       "1  \"Electric\"    Electric...  It's electric It's ...  \n",
       "2  \"Beach 2K20\"    (So you wanna go out? How you ...  \n",
       "3  \"Love Kills\"    If you're looking for love Get...  \n",
       "4  \"Time Machine\"    Hey, what did I do? Can't be...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the lyrics data\n",
    "lyrics_title = []\n",
    "lyrics = []\n",
    "artist = []\n",
    "\n",
    "for names in artists: \n",
    "    title_path = lyrics_folder+names\n",
    "    title_ly = os.listdir(title_path)\n",
    "    #print(title)\n",
    "    for ly in title_ly:\n",
    "        current_song_path = lyrics_folder+names+'/'+ly\n",
    "        lyrics_file = open(current_song_path, \"r\")\n",
    "        lyrics_content = (lyrics_file.read()).replace('\\n', \" \")\n",
    "        title = ly  \n",
    "          \n",
    "        artist.append(str(names))\n",
    "\n",
    "        lyrics_title.append(title)\n",
    "        lyrics.append(lyrics_content)\n",
    "        \n",
    "lyrics_data = pd.DataFrame({'artist':artist,'title':lyrics_title,'lyrics':lyrics})\n",
    "\n",
    "lyrics_data.head(5)  \n",
    "#.head(5)     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "\n",
    "twitter_data = pd.read_csv(twitter_folder + artist_files['cher'],\n",
    "                           sep=\"\\t\",\n",
    "                           quoting=3)\n",
    "\n",
    "twitter_data['artist'] = \"cher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_2 = pd.read_csv(#data_location + \n",
    "    twitter_folder + artist_files['robyn'],\n",
    "                             sep=\"\\t\",\n",
    "                             quoting=3)\n",
    "twitter_data_2['artist'] = \"robyn\"\n",
    "\n",
    "twitter_data = pd.concat([\n",
    "    twitter_data,twitter_data_2])\n",
    "    \n",
    "del(twitter_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hsmcnp</td>\n",
       "      <td>Country Girl</td>\n",
       "      <td>35152213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1302</td>\n",
       "      <td>1014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrormomy</td>\n",
       "      <td>Jeny</td>\n",
       "      <td>742153090850164742</td>\n",
       "      <td>Earth</td>\n",
       "      <td>81</td>\n",
       "      <td>514</td>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 &amp; 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anju79990584</td>\n",
       "      <td>anju</td>\n",
       "      <td>1496463006451974150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>140</td>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gallionjenna</td>\n",
       "      <td>J</td>\n",
       "      <td>3366479914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>556</td>\n",
       "      <td>csu</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcscomm</td>\n",
       "      <td>bcscomm</td>\n",
       "      <td>83915043</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>888</td>\n",
       "      <td>2891</td>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    screen_name          name                   id        location  \\\n",
       "0        hsmcnp  Country Girl             35152213             NaN   \n",
       "1    horrormomy          Jeny   742153090850164742           Earth   \n",
       "2  anju79990584          anju  1496463006451974150             NaN   \n",
       "3  gallionjenna             J           3366479914             NaN   \n",
       "4       bcscomm       bcscomm             83915043  Washington, DC   \n",
       "\n",
       "   followers_count  friends_count  \\\n",
       "0             1302           1014   \n",
       "1               81            514   \n",
       "2               13            140   \n",
       "3              752            556   \n",
       "4              888           2891   \n",
       "\n",
       "                                         description artist  \n",
       "0                                                NaN   cher  \n",
       "1           𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 & 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜   cher  \n",
       "2          163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡   cher  \n",
       "3                                                csu   cher  \n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...   cher  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word sentiment  score\n",
       "0         a+  positive      1\n",
       "1     abound  positive      1\n",
       "2    abounds  positive      1\n",
       "3  abundance  positive      1\n",
       "4   abundant  positive      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "#reading positive sentiment word file and assigning score +1\n",
    "pos_df = pd.read_csv(positive_words_file,\n",
    "                           sep=\"\\t\",\n",
    "                           encoding = 'latin-1', skiprows = 33)\n",
    "pos_df[\"sentiment\"] = \"positive\"\n",
    "pos_df = pos_df.rename(columns={pos_df.columns[0]: \"word\"})\n",
    "\n",
    "pos_df[\"score\"] = 1\n",
    "\n",
    "pos_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word sentiment  score\n",
       "0     2-faced  negative     -1\n",
       "1     2-faces  negative     -1\n",
       "2    abnormal  negative     -1\n",
       "3     abolish  negative     -1\n",
       "4  abominable  negative     -1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading negative sentiment word file and assigning score -1\n",
    "\n",
    "neg_df = pd.read_csv(negative_words_file,\n",
    "                           sep=\"\\t\",\n",
    "                           encoding = 'latin-1', skiprows = 33)\n",
    "#neg_df.head(35)\n",
    "\n",
    "neg_df[\"sentiment\"] = \"negative\"\n",
    "neg_df = neg_df.rename(columns={neg_df.columns[0]: \"word\"})\n",
    "neg_df[\"score\"] = -1\n",
    "neg_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abba</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abduction</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word sentiment  score\n",
       "0      abandon  negative     -1\n",
       "1    abandoned  negative     -1\n",
       "2  abandonment  negative     -1\n",
       "3         abba  positive      1\n",
       "4    abduction  negative     -1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading tidytext sentiment file and assigning score -1 and +1\n",
    "tidy_df = pd.read_csv(tidy_text_file,\n",
    "                           sep=\"\\t\",\n",
    "                           encoding = 'latin-1')#, skiprows = 33)\n",
    "tidy_df = tidy_df.drop(['lexicon'],axis=1)\n",
    "tidy_df[\"score\"] = tidy_df[\"sentiment\"].map({'positive':1, 'negative':-1})\n",
    "tidy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abundance</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abundant</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word sentiment  score\n",
       "0         a+  positive      1\n",
       "1     abound  positive      1\n",
       "2    abounds  positive      1\n",
       "3  abundance  positive      1\n",
       "4   abundant  positive      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joining all the dataframes after removing duplictaes\n",
    "\n",
    "sentiment_data = pd.concat([pos_df,neg_df,tidy_df]).drop_duplicates(subset=['word']).reset_index(drop=True)\n",
    "sentiment_data.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting list of positive and negative words  and score \n",
    "\n",
    "word_list = sentiment_data[\"word\"].tolist()\n",
    "word_sentiment_score = sentiment_data[\"score\"].tolist()\n",
    "\n",
    "#converting two lists into a single dictionary \n",
    "word_dict = dict(zip(word_list, word_sentiment_score))\n",
    "#word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating sentiment score. (referenced from book)\n",
    "\n",
    "def score_sentiment(tokens):\n",
    "    sentiment_score = 0\n",
    "    for word in tokens:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(tokens) if len(tokens)>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_includemeout.txt</td>\n",
       "      <td>\"Include Me Out\"    It is really very simple J...</td>\n",
       "      <td>[really, simple, single, pulse, repeated, regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_electric.txt</td>\n",
       "      <td>\"Electric\"    Electric...  It's electric It's ...</td>\n",
       "      <td>[electric, natural, high, dont, always, know, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   title  \\\n",
       "0  robyn  robyn_includemeout.txt   \n",
       "1  robyn      robyn_electric.txt   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  \"Include Me Out\"    It is really very simple J...   \n",
       "1  \"Electric\"    Electric...  It's electric It's ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [really, simple, single, pulse, repeated, regu...  \n",
       "1  [electric, natural, high, dont, always, know, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning the lyrics data \n",
    "\n",
    "my_pipeline_lyrics = [remove_song_title,lower_case, remove_punctuation,remove_stop, tokenize]\n",
    "\n",
    "lyrics_data[\"tokens\"] = lyrics_data[\"lyrics\"].apply(prepare,pipeline=my_pipeline_lyrics)\n",
    "lyrics_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Include Me Out</td>\n",
       "      <td>\"Include Me Out\"    It is really very simple J...</td>\n",
       "      <td>[really, simple, single, pulse, repeated, regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Electric</td>\n",
       "      <td>\"Electric\"    Electric...  It's electric It's ...</td>\n",
       "      <td>[electric, natural, high, dont, always, know, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist           title                                             lyrics  \\\n",
       "0  robyn  Include Me Out  \"Include Me Out\"    It is really very simple J...   \n",
       "1  robyn        Electric  \"Electric\"    Electric...  It's electric It's ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [really, simple, single, pulse, repeated, regu...  \n",
       "1  [electric, natural, high, dont, always, know, ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting songs title \n",
    "pipeline = [get_song_title]\n",
    "lyrics_data[\"title\"] = lyrics_data[\"lyrics\"].apply(prepare,pipeline=pipeline)\n",
    "lyrics_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Include Me Out</td>\n",
       "      <td>\"Include Me Out\"    It is really very simple J...</td>\n",
       "      <td>[really, simple, single, pulse, repeated, regu...</td>\n",
       "      <td>0.047210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Electric</td>\n",
       "      <td>\"Electric\"    Electric...  It's electric It's ...</td>\n",
       "      <td>[electric, natural, high, dont, always, know, ...</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Beach 2K20</td>\n",
       "      <td>\"Beach 2K20\"    (So you wanna go out? How you ...</td>\n",
       "      <td>[wanna, go, gonna, get, ok, call, someone, alr...</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Love Kills</td>\n",
       "      <td>\"Love Kills\"    If you're looking for love Get...</td>\n",
       "      <td>[youre, looking, love, get, heart, made, steel...</td>\n",
       "      <td>-0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Time Machine</td>\n",
       "      <td>\"Time Machine\"    Hey, what did I do? Can't be...</td>\n",
       "      <td>[hey, cant, believe, fit, threw, stupid, wante...</td>\n",
       "      <td>-0.062992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist           title                                             lyrics  \\\n",
       "0  robyn  Include Me Out  \"Include Me Out\"    It is really very simple J...   \n",
       "1  robyn        Electric  \"Electric\"    Electric...  It's electric It's ...   \n",
       "2  robyn      Beach 2K20  \"Beach 2K20\"    (So you wanna go out? How you ...   \n",
       "3  robyn      Love Kills  \"Love Kills\"    If you're looking for love Get...   \n",
       "4  robyn    Time Machine  \"Time Machine\"    Hey, what did I do? Can't be...   \n",
       "\n",
       "                                              tokens  sentiment_scores  \n",
       "0  [really, simple, single, pulse, repeated, regu...          0.047210  \n",
       "1  [electric, natural, high, dont, always, know, ...          0.058824  \n",
       "2  [wanna, go, gonna, get, ok, call, someone, alr...          0.151163  \n",
       "3  [youre, looking, love, get, heart, made, steel...         -0.098361  \n",
       "4  [hey, cant, believe, fit, threw, stupid, wante...         -0.062992  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying sentiment score function to lyrics \n",
    "lyrics_data['sentiment_scores'] =  lyrics_data['tokens'].apply(score_sentiment)\n",
    "lyrics_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "\n",
    "#### Average sentiment per song of an artist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     0.050884\n",
       "robyn    0.061790\n",
       "Name: sentiment_scores, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data.groupby('artist')['sentiment_scores'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q1: Overall, which artist has the higher average sentiment per song?** \n",
    "\n",
    "A: Artist **Robyn** has the highest average sentiment score per song.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "#### First artist highest and lowest sentiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robyn \n",
    "#### Highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Baby Forgive Me</td>\n",
       "      <td>\"Baby Forgive Me\"    Here come the night In yo...</td>\n",
       "      <td>[come, night, eyes, baby, brave, wise, like, m...</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist            title                                             lyrics  \\\n",
       "64  robyn  Baby Forgive Me  \"Baby Forgive Me\"    Here come the night In yo...   \n",
       "\n",
       "                                               tokens  sentiment_scores  \n",
       "64  [come, night, eyes, baby, brave, wise, like, m...              0.52  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robyn = lyrics_data.loc[lyrics_data['artist']=='robyn']\n",
    "highest = robyn.loc[robyn[\"sentiment_scores\"] == robyn[\"sentiment_scores\"].max()]\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song with highest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64    Baby Forgive Me\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Song with highest sentiment:\")\n",
    "\n",
    "robyn[\"title\"].loc[robyn[\"sentiment_scores\"] == robyn[\"sentiment_scores\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>robyn</td>\n",
       "      <td>Don't Fucking Tell Me What To Do</td>\n",
       "      <td>\"Don't Fucking Tell Me What To Do\"    My drink...</td>\n",
       "      <td>[drinking, killing, drinking, killing, drinkin...</td>\n",
       "      <td>-0.517241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist                             title  \\\n",
       "53  robyn  Don't Fucking Tell Me What To Do   \n",
       "\n",
       "                                               lyrics  \\\n",
       "53  \"Don't Fucking Tell Me What To Do\"    My drink...   \n",
       "\n",
       "                                               tokens  sentiment_scores  \n",
       "53  [drinking, killing, drinking, killing, drinkin...         -0.517241  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest = robyn.loc[robyn[\"sentiment_scores\"] == robyn[\"sentiment_scores\"].min()]\n",
    "lowest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song with Lowest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53    Don't Fucking Tell Me What To Do\n",
       "75    Don't Fucking Tell Me What To Do\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Song with Lowest sentiment:\")\n",
    "\n",
    "robyn[\"title\"].loc[robyn[\"sentiment_scores\"] == robyn[\"sentiment_scores\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: For your first artist, what songs have the highest and lowest sentiments? Print those songs to the screen.**\n",
    "\n",
    "A: For artist Robyn song titled **\"Baby Forgive Me\"** has highest sentiments with **score 0.52** and song titled **\"Don't Fucking Tell Me What To Do\"** has lowest sentiments with **score -0.517** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "#### Second artist highest and lowest sentiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cher \n",
    "#### Highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>cher</td>\n",
       "      <td>My Love</td>\n",
       "      <td>\"My Love\"    When I go away I know my heart ca...</td>\n",
       "      <td>[go, away, know, heart, stay, love, understood...</td>\n",
       "      <td>0.52439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist    title                                             lyrics  \\\n",
       "119   cher  My Love  \"My Love\"    When I go away I know my heart ca...   \n",
       "\n",
       "                                                tokens  sentiment_scores  \n",
       "119  [go, away, know, heart, stay, love, understood...           0.52439  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cher = lyrics_data.loc[lyrics_data['artist']=='cher']\n",
    "highest = cher.loc[cher[\"sentiment_scores\"] == cher[\"sentiment_scores\"].max()]\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cher song with highest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119    My Love\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" Cher song with highest sentiment:\")\n",
    "\n",
    "cher[\"title\"].loc[cher[\"sentiment_scores\"] == cher[\"sentiment_scores\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>cher</td>\n",
       "      <td>Bang-Bang</td>\n",
       "      <td>\"Bang-Bang\"    Bang bang you shot me down Bang...</td>\n",
       "      <td>[bang, bang, shot, bang, bang, hit, ground, ba...</td>\n",
       "      <td>-0.410405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist      title                                             lyrics  \\\n",
       "145   cher  Bang-Bang  \"Bang-Bang\"    Bang bang you shot me down Bang...   \n",
       "\n",
       "                                                tokens  sentiment_scores  \n",
       "145  [bang, bang, shot, bang, bang, hit, ground, ba...         -0.410405  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest = cher.loc[cher[\"sentiment_scores\"] == cher[\"sentiment_scores\"].min()]\n",
    "lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher song with Lowest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "145    Bang-Bang\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cher song with Lowest sentiment:\")\n",
    "\n",
    "cher[\"title\"].loc[cher[\"sentiment_scores\"] == cher[\"sentiment_scores\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q3: For your second artist, what songs have the highest and lowest sentiments? Print those songs to the screen.**\n",
    "\n",
    "A: For artist Cher song titled **\"My Love\"** has highest sentiments with **score 0.524** and song titled **\"Bang-Bang\"** has lowest sentiments with **score -0.41** \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "**Q4: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lyrics_data.groupby('artist')['sentiment_scores'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)\n",
    "plt.title(\"Sentiment Scores of Cher and Robyn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see in above figure overall robyn's lyrics sentiments seems have higher positive sentiments than cher sentiment with few exceptions on cher's lyrics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach:**\n",
    "\n",
    "For twiter description sentiment analysis we need to combine the scoer of both emoji and text. For extracting emoji score I will be making dictionary of 30 positive and 30 negative emojis picked from the most trendy emoji in the link provided which will be later analyzed with text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive emojis \n",
    "pos_emojis = {  '\\U0001F495', '\\U0001F308', '\\U0001F49C','\\U0001f600', '\\U0001F601',\n",
    "              '\\U0001F60A', '\\U0001F607', '\\U0001F970',\"\\u2728\", '\\U0001F618', \n",
    "              '\\U0001F60D', '\\U0001F60B', '\\U0001F61C','\\U0001F92A', '\\U0001F61D',\n",
    "              '\\U0001F911', '\\U0001F917','\\U0001F92D','\\U0001F60E', '\\U0001F49D', \n",
    "               '\\u2764\\ufe0f', '\\U0001F48F', '\\U0001F913', '\\U0001F4AF', '\\U0001F619', \n",
    "              '\\U0001F64C', '\\U0001F44F', '\\U0001F973', '\\U0001F929','\\U0001F602'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_emojis\n",
    "#len(pos_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative emojis \n",
    "\n",
    "neg_emojis= { '\\U0001F62A', '\\U0001F637', '\\U0001F912', '\\U0001F915', '\\U0001F922', \n",
    "             '\\U0001F92E', '\\U0001F927', '\\U0001F975', '\\U0001F615', '\\U0001F61F',\n",
    "             '\\U0001F641', '\\U0001F641', '\\U0001F62E', '\\U0001F62F', '\\U0001F632', \n",
    "             '\\U0001F97A', '\\U0001F622', '\\U0001F630', '\\U0001F625', '\\U0001F62D', \n",
    "             '\\U0001F616', '\\U0001F61E', '\\U0001F613', '\\U0001F624', '\\U0001F621', \n",
    "             '\\U0001F92C', '\\U0001F494', '\\U0001F44E', '\\U0001F62C', '\\U0001F63F', \n",
    "             '\\U0001F623'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neg_emojis\n",
    "#len(neg_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making disctionary of positive and negative emojis with their corresponding score 1 and -1\n",
    "pos_score = 1\n",
    "neg_score = -1 \n",
    "\n",
    "emo_dict = {}\n",
    "\n",
    "for emoji in pos_emojis:\n",
    "    emo_dict[emoji] = pos_score\n",
    "    \n",
    "for emoji in neg_emojis:\n",
    "    emo_dict[emoji] = neg_score\n",
    "\n",
    "#emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting relevant columns\n",
    "twitter_df = twitter_data[['description','artist']]\n",
    "#twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling null values\n",
    "twitter_df = twitter_df.fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>cher</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 &amp; 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "      <td>cher</td>\n",
       "      <td>[𝙿𝚛𝚘𝚞𝚍, 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛, 𝚘𝚏, 𝚖𝚎𝚜𝚜𝚢, 𝚋𝚞𝚗𝚜, 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "      <td>cher</td>\n",
       "      <td>[163㎝／愛かっぷ💜26歳🍒, 工〇好きな女の子💓, フォローしてくれたらdmします🧡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csu</td>\n",
       "      <td>cher</td>\n",
       "      <td>[csu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>cher</td>\n",
       "      <td>[writer, washinformer, spelmancollege, alumna,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description artist  \\\n",
       "0                                                      cher   \n",
       "1           𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 & 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜   cher   \n",
       "2          163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡   cher   \n",
       "3                                                csu   cher   \n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...   cher   \n",
       "\n",
       "                                              tokens  \n",
       "0                                                 []  \n",
       "1      [𝙿𝚛𝚘𝚞𝚍, 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛, 𝚘𝚏, 𝚖𝚎𝚜𝚜𝚢, 𝚋𝚞𝚗𝚜, 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜]  \n",
       "2      [163㎝／愛かっぷ💜26歳🍒, 工〇好きな女の子💓, フォローしてくれたらdmします🧡]  \n",
       "3                                              [csu]  \n",
       "4  [writer, washinformer, spelmancollege, alumna,...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning twitter description\n",
    "my_pipeline_twitter = [lower_case, remove_punctuation,remove_stop, tokenize]\n",
    "\n",
    "twitter_df[\"tokens\"] = twitter_df[\"description\"].apply(prepare,pipeline=my_pipeline_twitter)\n",
    "\n",
    "twitter_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_sentiment(tokens):\n",
    "#     sentiment_score = 0\n",
    "#     for word in tokens:\n",
    "#         if word in word_dict:\n",
    "#             sentiment_score += word_dict[word]\n",
    "#     return sentiment_score / len(tokens) if len(tokens)!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sentiment_score for text\n",
    "def sentiment_score(tokens):\n",
    "    sentiment_score = 0\n",
    "    for word in tokens:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / (len(tokens)) if len(tokens)!=0 else 0\n",
    "    \n",
    "\n",
    "#define sentiment_score for emojis\n",
    "def emoji_score(tokens):\n",
    "    emoji_score = 0\n",
    "    for word in tokens:\n",
    "        if word in emo_dict:\n",
    "            emoji_score += emo_dict[word]\n",
    "    return emoji_score / (len(tokens)) if len(tokens)!=0 else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>emoji_score</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>cher</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 &amp; 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "      <td>cher</td>\n",
       "      <td>[𝙿𝚛𝚘𝚞𝚍, 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛, 𝚘𝚏, 𝚖𝚎𝚜𝚜𝚢, 𝚋𝚞𝚗𝚜, 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "      <td>cher</td>\n",
       "      <td>[163㎝／愛かっぷ💜26歳🍒, 工〇好きな女の子💓, フォローしてくれたらdmします🧡]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csu</td>\n",
       "      <td>cher</td>\n",
       "      <td>[csu]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>cher</td>\n",
       "      <td>[writer, washinformer, spelmancollege, alumna,...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description artist  \\\n",
       "0                                                      cher   \n",
       "1           𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 & 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜   cher   \n",
       "2          163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡   cher   \n",
       "3                                                csu   cher   \n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...   cher   \n",
       "\n",
       "                                              tokens  sentiment_scores  \\\n",
       "0                                                 []          0.000000   \n",
       "1      [𝙿𝚛𝚘𝚞𝚍, 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛, 𝚘𝚏, 𝚖𝚎𝚜𝚜𝚢, 𝚋𝚞𝚗𝚜, 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜]          0.000000   \n",
       "2      [163㎝／愛かっぷ💜26歳🍒, 工〇好きな女の子💓, フォローしてくれたらdmします🧡]          0.000000   \n",
       "3                                              [csu]          0.000000   \n",
       "4  [writer, washinformer, spelmancollege, alumna,...          0.176471   \n",
       "\n",
       "   emoji_score  combined_score  \n",
       "0          0.0        0.000000  \n",
       "1          0.0        0.000000  \n",
       "2          0.0        0.000000  \n",
       "3          0.0        0.000000  \n",
       "4          0.0        0.176471  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying sentiment_score and  emoji_score functions to twitter description \n",
    "#and calculating combined score\n",
    "\n",
    "twitter_df['sentiment_scores'] =  twitter_df['tokens'].apply(sentiment_score)\n",
    "twitter_df['emoji_score'] =  twitter_df['tokens'].apply(emoji_score)\n",
    "\n",
    "twitter_df['combined_score']= twitter_df['sentiment_scores'] + twitter_df['emoji_score']\n",
    "twitter_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing without removing stop words\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# def sentiment_score_new(text):\n",
    "#     sentiment_score = 0\n",
    "#     bag_of_words = word_tokenize(text.lower())\n",
    "#     for word in bag_of_words:\n",
    "#         if word in word_dict:\n",
    "#             sentiment_score += word_dict[word]\n",
    "    \n",
    "#     return sentiment_score / (len(bag_of_words)) if len(bag_of_words)>0 else 0\n",
    "\n",
    "# def new_emoji_score(text):\n",
    "#     emoji_score = 0\n",
    "#     bag_of_words = word_tokenize(text.lower())\n",
    "#     for word in bag_of_words:\n",
    "#         if word in emo_dict:\n",
    "#             emoji_score += emo_dict[word]\n",
    "#     return emoji_score / len(bag_of_words) if len(bag_of_words)>0 else 0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df['description'] = twitter_df['description'].apply(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df['sentiment_scores_n'] =  twitter_df['description'].apply(sentiment_score_new)\n",
    "# twitter_df['emoji_score_n'] =  twitter_df['description'].apply(new_emoji_score)\n",
    "\n",
    "# twitter_df['combined_score_n']= twitter_df['sentiment_scores_n'] + twitter_df['emoji_score_n']\n",
    "# twitter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "####  Average sentiment of your two artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     0.047773\n",
       "robyn    0.042850\n",
       "Name: combined_score, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting average\n",
    "twitter_df.groupby('artist')['combined_score'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5: What is the average sentiment of your two artists?**\n",
    "\n",
    "A: The average sentiments of **Cher** is **0.047** and **Robyn** is **0.0428**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "\n",
    "**Most popular positive and negative emoji for each artist**\n",
    "\n",
    "**Robyn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset for robyn descriptio. data\n",
    "robyn_df = twitter_df[twitter_df['artist'] == 'robyn']\n",
    "#robyn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular positive Emojis for Robyn is:\n",
      "[('❤️', 987), ('✨', 751)]\n"
     ]
    }
   ],
   "source": [
    "robyn_positive_emojis = []\n",
    "for i in robyn_df['tokens']:\n",
    "    for token in i:\n",
    "        if token in pos_emojis:\n",
    "            robyn_positive_emojis.append(token)\n",
    "\n",
    "robyn_positive_emojis_count = Counter(robyn_positive_emojis)\n",
    "print('Most popular positive Emojis for Robyn is:')\n",
    "print(robyn_positive_emojis_count.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular negative Emojis for Robyn is:\n",
      "[('😷', 25), ('😬', 17)]\n"
     ]
    }
   ],
   "source": [
    "robyn_negative_emojis = []\n",
    "for i in robyn_df['tokens']:\n",
    "    for token in i:\n",
    "        if token in neg_emojis:\n",
    "            robyn_negative_emojis.append(token)\n",
    "\n",
    "robyn_negative_emojis_count = Counter(robyn_negative_emojis)\n",
    "print('Most popular negative Emojis for Robyn is:')\n",
    "print(robyn_negative_emojis_count.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsent for cher description data\n",
    "cher_df = twitter_df[twitter_df['artist'] == 'cher']\n",
    "\n",
    "#cher_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular positive Emojis for Cher is:\n",
      "[('❤️', 14715), ('✨', 8343)]\n"
     ]
    }
   ],
   "source": [
    "cher_positive_emojis = []\n",
    "for i in cher_df['tokens']:\n",
    "    for token in i:\n",
    "        if token in pos_emojis:\n",
    "            cher_positive_emojis.append(token)\n",
    "\n",
    "cher_positive_emojis_count = Counter(cher_positive_emojis)\n",
    "print('Most popular positive Emojis for Cher is:')\n",
    "print(cher_positive_emojis_count.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular negative Emojis for Cher is:\n",
      "[('😷', 734), ('💔', 368)]\n"
     ]
    }
   ],
   "source": [
    "cher_negative_emojis = []\n",
    "for i in cher_df['tokens']:\n",
    "    for token in i:\n",
    "        if token in neg_emojis:\n",
    "            cher_negative_emojis.append(token)\n",
    "\n",
    "cher_negative_emojis_count = Counter(cher_negative_emojis)\n",
    "print('Most popular negative Emojis for Cher is:')\n",
    "print(cher_negative_emojis_count.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Q: Which positive emoji is the most popular for each artist? Which negative emoji?**\n",
    "\n",
    "A: For artist Robyn most popular positive emoji is ❤️ with frequency **987** and the most popular negative emoji is 😷  with a frequency of **25**.\n",
    "\n",
    "Simlarly, for artist Cher most popular  positive emoji is ❤️ with frequency **14715** and negative emoji is 😷 with frequency **734**.  \n",
    "\n",
    "\n",
    "**Note:** The popular emoji depend on the the emojis which are manually assigned to pos_emojis(30 count) and neg_emojis(30 count). If we assign more positive and negative emojis the results can/might look different. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
